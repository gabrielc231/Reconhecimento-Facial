{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40b90843"
      },
      "source": [
        "<img src=\"http://meusite.mackenzie.br/rogerio/mackenzie_logo/UPM.2_horizontal_vermelho.jpg\"  width=300, align=\"right\">\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "# **Template para o Colab do Projeto Semestral**\n",
        "---\n",
        "\n",
        "Atenção, podem ser que nem todas as tarefas sejam executadas no Colab (a aplicação por exemplo, pode estar hospedada no streamlit cloud). Mas a maior parte pode estar aqui ou ao menos indicada e comentada.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Além disso a entrega deve incluir:\n",
        "\n",
        "1. **Um GitHub público do projeto**\n",
        "2. **Código completo e executável em um notebook Python (este template)**\n",
        "3. **Uma aplicação streamlit para consumo do modelo**\n",
        "4. **Um texto/artigo do projeto**\n",
        "5. **Um vídeo (link YouTube ou outro) de no máximo 3min de apresentação do projeto**\n",
        "\n",
        "Um **`readme.md`** no GitHub público do projeto deve indicar (um índice) cada uma dessas entregas.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qR6kcPlTeV_n"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYx9D4GZA5o9",
        "cellView": "form"
      },
      "source": [
        "#@title **Identificação do Grupo**\n",
        "\n",
        "#@markdown Integrantes do Grupo, nome completo em orgem alfabética (*informe \\<RA\\>,\\<nome\\>*)\n",
        "Aluno1 = '10403025, Gabriel Gonzaga Chung' #@param {type:\"string\"}\n",
        "Aluno2 = '10403462, Igor Benites Moura' #@param {type:\"string\"}\n",
        "Aluno3 = ' 10401873, Rodrigo Machado de Assis Oliveira de Lima' #@param {type:\"string\"}\n",
        "Aluno4 = 'None' #@param {type:\"string\"}\n",
        "Aluno5 = 'None' #@param {type:\"string\"}\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Assinale aqui a sua opção de Projeto\n",
        "Projeto = \"IA Aplicada a Imagens: Uso de Modelos de Redes Neurais\" #@param [\"IA Aplicada a Imagens: Uso de Modelos de Redes Neurais\", \"IA Aplicada a Documentos: Uso de Grandes Modelos de Linguagem Abertos\"]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-MbC50IHTmh3",
        "cellView": "form"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Resumo**\n",
        "\n",
        "Apresente um \"abstract\" do seu projeto.\n",
        "\n",
        "1. Objetivo do projeto\n",
        "2. Fontes dos dados e dados originais (coletados)\n",
        "3. Ferramentas/pacotes de IA a serem utilizados para a construção da solução\n",
        "4. Um prévia dos resultados."
      ],
      "metadata": {
        "id": "yxYbSf6mVM7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\"> O objetivo deste projeto é desenvolver um sistema capaz de classificar expressões faciais humanas em quatro categorias emocionais básicas: raiva, felicidade, tristeza e surpresa. Para isso, foi construída e treinada uma rede neural convolucional (CNN) utilizando imagens faciais em tons de cinza com resolução de 48x48 pixels. Os dados utilizados foram oriundos de fontes públicas como FER-2013 de M. Sambare e  e de coletas próprias, sendo organizados em diretórios por classe. As imagens passaram por técnicas de data augmentation para aumentar a variabilidade e robustez do treinamento. A solução foi implementada com auxílio das bibliotecas TensorFlow, Keras e NumPy, e a aplicação final foi integrada a uma interface interativa desenvolvida em Streamlit, permitindo que usuários submetam imagens e obtenham a predição da emoção predominante. Como resultado, o modelo alcançou uma acurácia de aproximadamente 74% na base de validação, demonstrando bom desempenho na tarefa de reconhecimento facial de emoções"
      ],
      "metadata": {
        "id": "G_46a-j8m6lB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Apresentação dos dados**\n",
        "\n",
        "Inclua link, amostras dos dados."
      ],
      "metadata": {
        "id": "ctroSu6jNABS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"justify\">\n",
        "\n",
        "# **Apresentação dos dados**\n",
        "\n",
        "O conjunto de dados utilizado no projeto é composto por imagens de expressões faciais organizadas em quatro classes principais: `angry` (raiva), `happy` (feliz), `sad` (triste) e `surprise` (surpresa). As imagens foram utilizadas no formato em **tons de cinza** com **resolução 48x48 pixels**, visando compatibilidade com a arquitetura da CNN e menor custo computacional.\n",
        "\n",
        "As imagens foram coletadas a partir do dataset **FER-2013** e complementadas com coletas próprias. Todas as imagens foram organizadas em pastas no formato esperado por `ImageDataGenerator` da biblioteca Keras, seguindo a estrutura:\n",
        "\n"
      ],
      "metadata": {
        "id": "InjQe3Qlx06r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Link de referência:\n",
        "- FER-2013: [https://www.kaggle.com/datasets/msambare/fer2013](https://www.kaggle.com/datasets/msambare/fer2013)\n",
        "\n",
        "---\n",
        "\n",
        "### Exemplos de amostras:\n",
        "\n",
        "| Angry | Happy | Sad | Surprise |\n",
        "|-------|-------|-----|----------|\n",
        "| ![angry](https://i.imgur.com/ISZzER5.png) | ![happy](https://i.imgur.com/Nh3JHMS.png) | ![sad](https://i.imgur.com/KqZ9Zx6.png) | ![surprise](https://i.imgur.com/O0xSZHt.png) |\n",
        "\n",
        "*(Imagens ilustrativas — substitua por amostras reais se desejar)*\n",
        "\n",
        "---\n",
        "\n",
        "### Distribuição dos dados (treinamento):\n",
        "\n",
        "| Classe     | Quantidade |\n",
        "|------------|------------|\n",
        "| Happy      | 9555       |\n",
        "| Sad        | 7921       |\n",
        "| Angry      | 5495       |\n",
        "| Surprise   | 5290       |\n",
        "| **Total**  | **28.261** |\n",
        "\n",
        "O dataset apresenta certo desbalanceamento, que foi corrigido no treinamento por meio da atribuição de **pesos por classe** com base na proporção de dados.\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "BJi4uDFSx8iv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abaixo algumas seções de exemplo\n",
        "\n",
        "> Pode haver mais, dependendo da sua aplicação. Para cada seção faça comentários explicando a tarefa e comentando/sumarizando os resultados."
      ],
      "metadata": {
        "id": "rUPW64ESNJgR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importações de Pacotes**"
      ],
      "metadata": {
        "id": "F37jW1uUQ2FU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Foram importados (e instalados se necessário) os pacotes necessários para a criação do modelo, neste caso: \\\n",
        "\\\n",
        "**Tensorflow**: Framework de aprendizado de máquina. \\\n",
        "**Keras**: API de alto nível para construir e treinar modelos. \\\n",
        "**Numpy**: Computação numérica eficiente com arrays.\\\n",
        "**Matplotlib**: Criação de gráficos para visualização.\\"
      ],
      "metadata": {
        "id": "hwGqTfjfQ-Yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "zAHhnfFN2s3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1aa12f8-97b0-461b-b7c6-136b0c58b8df"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "Lvntdd69Q8l9"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configuração de GPU**"
      ],
      "metadata": {
        "id": "ouo-h-eyUaTi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testa para ver se alguma **GPU** foi identificada, se sim configura crescimento de memória."
      ],
      "metadata": {
        "id": "ViwJshZ3UlUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === GPU Configuration ===\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)"
      ],
      "metadata": {
        "id": "fQ8W8NCdUjxK"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preparação e transformação dos dados**\n",
        "\n"
      ],
      "metadata": {
        "id": "GDzwn_5AMZ52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta etapa, as imagens faciais foram organizadas em pastas separadas por classe (`angry`, `happy`, `sad`, `surprise`).\n"
      ],
      "metadata": {
        "id": "cx80JIIFs9dC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Classes ===\n",
        "classes_usadas = ['angry', 'happy', 'sad', 'surprise']"
      ],
      "metadata": {
        "id": "QS-dKYJxVJva"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Foram definidos os diretórios das dados de **treino** e **validação**."
      ],
      "metadata": {
        "id": "qwnxOfHkVSIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Diretórios ===\n",
        "train_dir = 'data/train'\n",
        "val_dir = 'data/test'"
      ],
      "metadata": {
        "id": "OjK8q5nRVaE3"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Foi definido pesos para cada classe (**class weight**), visto que os dados estão desbalanceados entre cada classe <br> (tem mais dados de **\"happy\"** que **\"surprise\"**, por exemplo)."
      ],
      "metadata": {
        "id": "QaxpYB70WmWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Class Weights ===\n",
        "n_classes = len(classes_usadas)\n",
        "n_data = [0] * n_classes\n",
        "n_data[0] = 5495 # angry\n",
        "n_data[1] = 9555 # happy\n",
        "n_data[2] = 7921 # sad\n",
        "n_data[3] = 5290 # surprise\n",
        "\n",
        "total_data = sum(n_data)\n",
        "class_weights = {\n",
        "    i: total_data / (n_data[i] * n_classes) for i in range(n_classes)\n",
        "}"
      ],
      "metadata": {
        "id": "rMkOiU9TXeJQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Foi aplicado **data augmentation** com operações como rotação, zoom, translação e espelhamento horizontal para **aumentar a variabilidade** do conjunto de treinamento e **reduzir o overfitting**. Além disso, foram calculados **pesos por classe** com base no número de exemplos por emoção, equilibrando o aprendizado da rede em um cenário desbalanceado."
      ],
      "metadata": {
        "id": "t9m-x8iBYAmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Data Augmentation ===\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "zGc0mB0JX8s3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As imagens foram utilizadas em tons de cinza com dimensão de **48x48 pixels**.\n"
      ],
      "metadata": {
        "id": "MIZHhodwVIAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Dados de Treino ===\n",
        "train_data = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(48, 48),\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical',\n",
        "    classes=classes_usadas,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# === Dados de Validação ===\n",
        "val_data = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(48, 48),\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical',\n",
        "    classes=classes_usadas,\n",
        "    batch_size=64,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "AgDBlS-JVP5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e7fd98-2e1b-4b3c-e169-8b712b7bc637"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 4 classes.\n",
            "Found 0 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resumo dos dados:\n",
        "\n",
        "| Classe     | Quantidade |\n",
        "|------------|------------|\n",
        "| Happy      | 9555       |\n",
        "| Sad        | 7921       |\n",
        "| Angry      | 5495       |\n",
        "| Surprise   | 5290       |\n",
        "| **Total**  | **28.261** |"
      ],
      "metadata": {
        "id": "oF3l7tdWtNZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelo Implementado**"
      ],
      "metadata": {
        "id": "6kk5JHCLYkMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# === Modelo CNN ===\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(48, 48, 1)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "    Dropout(0.15),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(256, (3,3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(n_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "Y32TLlaHvpWH"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine Tuning do modelo**"
      ],
      "metadata": {
        "id": "iNMQ__e1tWW0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Foram testadas diferentes quantidades de filtros, camadas `Dropout`, e ajustes na função de ativação, tamanho dos kernels e taxa de aprendizado. O modelo final foi composto por **quatro blocos convolucionais com BatchNormalization, MaxPooling e Dropout**, seguido por camadas densas e softmax na saída."
      ],
      "metadata": {
        "id": "vJ8RyfBLvp-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Além disso, foi utilizado:\n",
        "- `EarlyStopping`: para interromper o treino ao detectar estagnação.\n",
        "- `ModelCheckpoint`: para salvar automaticamente o melhor modelo com base na acurácia de validação.\n",
        "- `Adam` com **learning rate ajustado (0.0005)** para convergência mais estável."
      ],
      "metadata": {
        "id": "jZ_9QABrv2ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Compilação ===\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# === Callbacks ===\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=6, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('models/best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')"
      ],
      "metadata": {
        "id": "CjGT10ffv8Td",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "outputId": "dbb5df87-98b4-4be1-8e57-887494e688e4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m2,052\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,052</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,571,972\u001b[0m (6.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,571,972</span> (6.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,571,012\u001b[0m (5.99 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,571,012</span> (5.99 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Treinamento do Modelo**"
      ],
      "metadata": {
        "id": "qfLllrWNzy05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "40c4ICF_z_p9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Treinamento ===\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=100,\n",
        "    callbacks=[early_stopping, checkpoint],\n",
        "    class_weight=class_weights\n",
        ")"
      ],
      "metadata": {
        "id": "xfYiVxFNz5oD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "19fe7bc8-2791-42bf-ac05-dc9b0ddc9949"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The PyDataset has length 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-e75c4a8aeab8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# === Treinamento ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\u001b[0m in \u001b[0;36mget_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m             ]\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The PyDataset has length 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The PyDataset has length 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5_6t_V0Nz_Np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Salvar Modelo ===\n",
        "model.save(\"models/final_model.h5\")"
      ],
      "metadata": {
        "id": "g2Suk3kZz9kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Avaliação do modelo**\n",
        "\n"
      ],
      "metadata": {
        "id": "p1Evo4PmNhBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<div align=\"justify\">\n",
        "\n",
        "# **Avaliação do Modelo (com análise gráfica)**\n",
        "\n",
        "Após o treinamento, o modelo foi avaliado no conjunto de validação. O resultado foi uma acurácia de aproximadamente **74,5%**, o que representa um desempenho bastante satisfatório, considerando a **ausência de técnicas de transfer learning**, a presença de **dados desbalanceados** entre as classes e a **complexidade natural da tarefa de classificação de emoções faciais**.\n",
        "\n",
        "A **curva de acurácia** apresentou crescimento consistente ao longo das épocas, com a acurácia de validação acompanhando de perto a de treinamento, indicando **boa generalização** e **ausência de overfitting significativo**. Já o **gráfico da função de perda (loss)** mostrou uma redução progressiva da perda tanto no conjunto de treinamento quanto no de validação, com pequenas oscilações naturais em razão da variação nos batches. Essa tendência reforça que o modelo foi capaz de aprender os padrões relevantes nas imagens sem memorizar os dados.\n",
        "\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "_psReYiKQhKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Avaliação final ===\n",
        "loss, acc = model.evaluate(val_data)\n",
        "print(f\"Acurácia em validação: {acc:.2f}\")\n",
        "\n",
        "# === Gráficos de desempenho ===\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Acurácia por época\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Treinamento')\n",
        "plt.plot(history.history['val_accuracy'], label='Validação')\n",
        "plt.title('Acurácia por época')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Perda por época\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Treinamento')\n",
        "plt.plot(history.history['val_loss'], label='Validação')\n",
        "plt.title('Perda (Loss) por época')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QhkxaLgT0Xt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A **matriz de confusão** revelou que o modelo possui um bom equilíbrio entre as classes, acertando corretamente a maioria das amostras. No entanto, observou-se uma tendência de confusão entre as emoções `sad` e `angry`, o que é esperado dada a similaridade visual de certas expressões faciais nessas categorias. Por outro lado, emoções mais distintas como `happy` e `surprise` apresentaram altas taxas de acerto, refletindo maior separabilidade entre suas representações visuais.\n"
      ],
      "metadata": {
        "id": "vT5zaar97KGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Matriz de Confusão ===\n",
        "\n",
        "# Rótulos verdadeiros e previstos\n",
        "y_true = val_data.classes\n",
        "y_pred_probs = model.predict(val_data)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Geração e exibição da matriz\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes_usadas)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap='Blues', values_format='d')\n",
        "plt.title(\"Matriz de Confusão - Validação\")\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tnNMfhPk78t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por fim, a **distribuição das previsões por classe** foi visualmente coerente quando testada em imagens reais, por meio da interface construída com Streamlit, demonstrando a aplicabilidade prática do modelo em um sistema interativo de reconhecimento emocional."
      ],
      "metadata": {
        "id": "Z5yRQVor7MxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Consumo do modelo**"
      ],
      "metadata": {
        "id": "ViQfwNxkNj0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"justify\"> Para o consumo do modelo tivemos, subimos uma aplicação <strong>Streamlit</strong> que permite o usuário fornecer uma imagem, e quando apertado um botão chamado <em>\"Classificar Emoção\"</em>, são demonstrados a emoção reconhecida e uma distribuição de probabilidades."
      ],
      "metadata": {
        "id": "dfVtsvqQnaqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A aplicação está presente em:** https://face-recognit.streamlit.app/"
      ],
      "metadata": {
        "id": "yrub6bkXwORG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Referências**\n",
        "\n",
        "SAMBARE M. **FER-2013.** Disponível em: <https://www.kaggle.com/datasets/msambare/fer2013>. Acesso em: 28 maio 2025.\n",
        "\n",
        "MST. JEBA SHAZIDA. AffectNet. Disponível em: <https://www.kaggle.com/datasets/mstjebashazida/affectnet>. Acesso em: 28 maio 2025.\n",
        "\n",
        "KERAS. **Home - Keras Documentation**. Disponível em: <https://keras.io/>. Acesso em: 28 maio 2025.\n",
        "\n",
        "OPENCV. **OpenCV documentation index.** Disponível em: <https://docs.opencv.org/>. Acesso em: 28 maio 2025.\n",
        "\n",
        "TENSORFLOW. **TensorFlow.** Disponível em: <https://www.tensorflow.org/>. Acesso em: 09 abr. 2025.\n"
      ],
      "metadata": {
        "id": "7LtXrRFr4hg3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8crUBC3IQ3U_"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "46xyluh0pd7X"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BluFtfHuCGzm",
        "cellView": "form"
      },
      "source": [
        "#@title **Avaliação**\n",
        "GitHub = 10 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Implementacao_Model_Code = 10 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Aplicacao_Streamlit = 10 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Texto_Artigo  = 10 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Video = 10 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Geral = 10 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gqw7hUZHyle",
        "cellView": "form"
      },
      "source": [
        "#@title **Nota Final**\n",
        "\n",
        "nota = 2*GitHub + 4*Implementacao_Model_Code + 2*Aplicacao_Streamlit + 1*Texto_Artigo + 1*Video\n",
        "\n",
        "nota = nota / 10\n",
        "\n",
        "print(f'Nota final do trabalho {nota :.1f}')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "alunos = pd.DataFrame()\n",
        "\n",
        "lista_tia = []\n",
        "lista_nome = []\n",
        "\n",
        "for i in range(1,6):\n",
        "  exec(\"if Aluno\" + str(i) + \" !='None':  lista = Aluno\" + str(i) + \".split(','); lista_tia.append(lista[0]); lista_nome.append(lista[1].upper())\")\n",
        "\n",
        "alunos['tia'] = lista_tia\n",
        "alunos['nome'] = lista_nome\n",
        "alunos['nota'] = np.round(nota,1)\n",
        "print()\n",
        "display(alunos)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}